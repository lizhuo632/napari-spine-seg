{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from tqdm import trange\n",
    "\n",
    "data_path = '/share/data/CryoET_Data/lizhuo/data_for_liushuo/3D_training_data/mask5/l5-actin-1.tif'\n",
    "mask_sign = '_spine_result'\n",
    "mask_path = data_path.replace('.tif',mask_sign+'.tif')\n",
    "file_name = data_path.split('/')[-1].split('.')[0]\n",
    "mask_name = mask_path.split('/')[-1].split('.')[0]\n",
    "save_path = os.path.join(data_path.split(file_name)[0],'patchs')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "patch_size = 1024\n",
    "overlap_rate = 0.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def equalize_histogram_sqrt(image):\n",
    "\n",
    "    img_np = np.asarray(image)\n",
    "\n",
    "    # 计算原始直方图\n",
    "    histogram, bin_edges = np.histogram(img_np.flatten(), bins=256, range=(0, 256))\n",
    "\n",
    "    # 对直方图的值取平方根\n",
    "    histogram_sqrt = np.sqrt(histogram)\n",
    "\n",
    "    # 计算累计分布函数 (CDF)\n",
    "    cdf = histogram_sqrt.cumsum()\n",
    "    cdf_normalized = 255 * (cdf - cdf.min()) / (cdf.max() - cdf.min())\n",
    "    cdf_normalized = cdf_normalized.astype('uint8')\n",
    "\n",
    "    # 使用平方根处理后的 CDF 映射像素值\n",
    "    equalized_img_np = cdf_normalized[img_np]\n",
    "\n",
    "    # 将均衡化后的数组转换回图像\n",
    "    #equalized_image_pil = Image.fromarray(equalized_img_np)\n",
    "\n",
    "    return equalized_img_np\n",
    "\n",
    "def image_preprocess(img, percentile=99.5,equalize=False):\n",
    "#input: PIL image or np array\n",
    "#max percentile + normalize -> 0-255 int(uint8)\n",
    "#output: np array\n",
    "    if type(img) is np.ndarray:\n",
    "        img_np = img\n",
    "    else:\n",
    "        img_np = np.array(img)\n",
    "        #print(\"warning: input image is not np.ndarray\")\n",
    "\n",
    "    max_percentile = np.percentile(img_np, percentile)\n",
    "    img_np = np.minimum(img_np, max_percentile)\n",
    "    img_np = (img_np - np.min(img_np)) / (np.max(img_np) - np.min(img_np))\n",
    "    img_np = img_np * 255\n",
    "    img_np = img_np.astype(np.uint8)\n",
    "\n",
    "    if equalize:\n",
    "        img_np = equalize_histogram_sqrt(img_np)\n",
    "\n",
    "    return img_np\n",
    "\n",
    "def get_patch(data, patch_size, overlap_rate):\n",
    "    data_patch = []\n",
    "    for i in range(0, data.shape[1]-int(patch_size*(1-overlap_rate)), int(patch_size*(1-overlap_rate))):\n",
    "        for j in range(0, data.shape[2]-int(patch_size*(1-overlap_rate)), int(patch_size*(1-overlap_rate))):\n",
    "            data_patch.append(data[:,i:i+patch_size,j:j+patch_size])\n",
    "    return data_patch\n",
    "\n",
    "\n",
    "data_exists = os.path.exists(data_path)\n",
    "mask_exists = os.path.exists(mask_path)\n",
    "if data_exists:\n",
    "    data = tiff.imread(data_path)\n",
    "    if len(data.shape) == 2:\n",
    "        data = data[np.newaxis,...]\n",
    "    print('processing data with shape:', data.shape)\n",
    "    processed_data = np.zeros(data.shape)\n",
    "    for t in trange(data.shape[0]):\n",
    "        processed_data[t] = image_preprocess(data[t])\n",
    "    print('getting patchs...')\n",
    "    data_patch = get_patch(processed_data, patch_size, overlap_rate)\n",
    "    print('saving patchs...')\n",
    "    for i in trange(len(data_patch)):\n",
    "        tiff.imwrite(os.path.join(save_path, file_name+'-'+f\"{i:04d}\"+'.tif'), data_patch[i].astype(np.uint8))\n",
    "if mask_exists:\n",
    "    mask = tiff.imread(mask_path)\n",
    "    if len(mask.shape) == 2:\n",
    "        mask = mask[np.newaxis,...]\n",
    "    print('processing mask with shape:', mask.shape)\n",
    "    print('getting patchs...')\n",
    "    mask_patch = get_patch(mask, patch_size, overlap_rate)\n",
    "    print('saving patchs...')\n",
    "    for i in trange(len(data_patch)):\n",
    "        tiff.imwrite(os.path.join(save_path, mask_name+'-'+f\"{i:04d}\"+'.tif'), mask_patch[i].astype(np.uint16))\n",
    "\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from scipy.ndimage import find_objects, label\n",
    "from tqdm import trange\n",
    "\n",
    "#对文件夹下所有文件处理版\n",
    "\n",
    "# 设置文件夹路径\n",
    "data_folder = '/share/data/CryoET_Data/lizhuo/data_for_liushuo/3D_data_with_mask/l5'  # 文件夹路径\n",
    "mask_signs = ('_spine_result','-hwl-spine')\n",
    "patch_size = 1024\n",
    "overlap_rate = 0.5\n",
    "\n",
    "# 获取文件夹中所有的 .tif 文件\n",
    "tif_files = [f for f in os.listdir(data_folder) if f.endswith('.tif')]\n",
    "\n",
    "def equalize_histogram_sqrt(image):\n",
    "    img_np = np.asarray(image)\n",
    "    # 计算原始直方图\n",
    "    histogram, bin_edges = np.histogram(img_np.flatten(), bins=256, range=(0, 256))\n",
    "\n",
    "    # 对直方图的值取平方根\n",
    "    histogram_sqrt = np.sqrt(histogram)\n",
    "\n",
    "    # 计算累计分布函数 (CDF)\n",
    "    cdf = histogram_sqrt.cumsum()\n",
    "    cdf_normalized = 255 * (cdf - cdf.min()) / (cdf.max() - cdf.min())\n",
    "    cdf_normalized = cdf_normalized.astype('uint8')\n",
    "\n",
    "    # 使用平方根处理后的 CDF 映射像素值\n",
    "    equalized_img_np = cdf_normalized[img_np]\n",
    "\n",
    "    return equalized_img_np\n",
    "\n",
    "def image_preprocess(img, percentile=99.5, equalize=False):\n",
    "    # input: PIL image or np array\n",
    "    # max percentile + normalize -> 0-255 int(uint8)\n",
    "    # output: np array\n",
    "    if type(img) is np.ndarray:\n",
    "        img_np = img\n",
    "    else:\n",
    "        img_np = np.array(img)\n",
    "\n",
    "    max_percentile = np.percentile(img_np, percentile)\n",
    "    img_np = np.minimum(img_np, max_percentile)\n",
    "    img_np = (img_np - np.min(img_np)) / (np.max(img_np) - np.min(img_np))\n",
    "    img_np = img_np * 255\n",
    "    img_np = img_np.astype(np.uint8)\n",
    "\n",
    "    if equalize:\n",
    "        img_np = equalize_histogram_sqrt(img_np)\n",
    "\n",
    "    return img_np\n",
    "\n",
    "\n",
    "\n",
    "def filter_small(img, threshold):\n",
    "    result = np.array(img)\n",
    "    if len(result.shape) == 2:\n",
    "        # 使用 SciPy 的 label 函数标记连通区域\n",
    "        labeled_image, num_features = label(result)\n",
    "\n",
    "        # 获取每个区域的边界框\n",
    "        objects = find_objects(labeled_image)\n",
    "\n",
    "        for i, obj in enumerate(objects, start=1):\n",
    "            area = np.sum(labeled_image[obj] == i)\n",
    "            if area < threshold:\n",
    "                labeled_image[labeled_image == i] = 0\n",
    "            else:\n",
    "                labeled_image[labeled_image == i] = i\n",
    "\n",
    "        result = labeled_image\n",
    "    else:\n",
    "        for t in range(result.shape[0]):\n",
    "            labeled_image, num_features = label(result[t])\n",
    "            objects = find_objects(labeled_image)\n",
    "            for i, obj in enumerate(objects, start=1):\n",
    "                area = np.sum(labeled_image[obj] == i)\n",
    "                if area < threshold:\n",
    "                    labeled_image[labeled_image == i] = 0\n",
    "                else:\n",
    "                    labeled_image[labeled_image == i] = i\n",
    "            result[t] = labeled_image\n",
    "\n",
    "    return result\n",
    "\n",
    "def reset_id(segmentation):\n",
    "    # 获取唯一值\n",
    "    values = np.unique(segmentation)\n",
    "\n",
    "    # 检查是否需要重置 ID\n",
    "    if np.max(segmentation) == len(values) - 1:\n",
    "        return segmentation\n",
    "\n",
    "    # 创建新的分割 ID 数组\n",
    "    reset_id_seg = np.zeros_like(segmentation, dtype=int)\n",
    "    # 过滤掉0值\n",
    "    non_zero_values = values[values != 0]\n",
    "\n",
    "    # 使用 np.arange 生成新 ID\n",
    "    reset_id_seg[np.isin(segmentation, non_zero_values)] = np.arange(1, len(non_zero_values) + 1)[np.searchsorted(non_zero_values, segmentation[segmentation != 0])]\n",
    "\n",
    "    return reset_id_seg.astype(np.uint16)\n",
    "\n",
    "def get_patch(data, patch_size, overlap_rate):\n",
    "    data_patch = []\n",
    "    for i in range(0, data.shape[1] - int(patch_size * (1 - overlap_rate)), int(patch_size * (1 - overlap_rate))):\n",
    "        for j in range(0, data.shape[2] - int(patch_size * (1 - overlap_rate)), int(patch_size * (1 - overlap_rate))):\n",
    "            data_patch.append(data[:, i:i + patch_size, j:j + patch_size])\n",
    "    return data_patch\n",
    "\n",
    "\n",
    "# 遍历文件夹中的所有 .tif 文件\n",
    "for tif_file in tif_files:\n",
    "    print(f\"Processing file: {tif_file}\")\n",
    "\n",
    "    data_path = os.path.join(data_folder, tif_file)\n",
    "    file_name = tif_file.split('.')[0]\n",
    "    save_path = os.path.join(data_folder, 'patches')\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    if file_name.endswith(mask_signs):\n",
    "        data_type = 'mask'\n",
    "    else:\n",
    "        data_type = 'data'\n",
    "\n",
    "    if data_type == 'data':\n",
    "        data = tiff.imread(data_path)\n",
    "        if len(data.shape) == 2:\n",
    "            data = data[np.newaxis, ...]\n",
    "        print(f'Processing data with shape: {data.shape}')\n",
    "        processed_data = np.zeros(data.shape)\n",
    "        for t in trange(data.shape[0]):\n",
    "            processed_data[t] = image_preprocess(data[t])\n",
    "        print('Getting patches for data...')\n",
    "        data_patch = get_patch(processed_data, patch_size, overlap_rate)\n",
    "        print('Saving data patches...')\n",
    "        for i in trange(len(data_patch)):\n",
    "            patch_file = os.path.join(save_path, f\"{file_name}-{i:04d}.tif\")\n",
    "            tiff.imwrite(patch_file, data_patch[i].astype(np.uint8))\n",
    "\n",
    "    if data_type == 'mask':\n",
    "        mask = tiff.imread(data_path)\n",
    "        if len(mask.shape) == 2:\n",
    "            mask = mask[np.newaxis, ...]\n",
    "        print(f'Reset id with mask shape: {mask.shape}')\n",
    "        mask = filter_small(mask,0)\n",
    "        print('Getting patches for mask...')\n",
    "        mask_patch = get_patch(mask, patch_size, overlap_rate)\n",
    "        print('Saving mask patches...')\n",
    "        for i in trange(len(mask_patch)):\n",
    "            patch_file = os.path.join(save_path, f\"{file_name}-{i:04d}.tif\")\n",
    "            tiff.imwrite(patch_file, mask_patch[i].astype(np.uint16))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('All files processed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "\n",
    "#from scipy.ndimage.filter import gaussian_filter\n",
    "from natsort import natsorted\n",
    "from tqdm import trange\n",
    "\n",
    "# def get_gaussian(s, sigma=4.0/8) -> np.ndarray:\n",
    "# \ttemp = np.zeros(s)\n",
    "# \tcoords = [i // 2 for i in s]\n",
    "# \tsigmas = [i * sigma for i in s]\n",
    "# \ttemp[tuple(coords)] = 1\n",
    "# \tgaussian_map = gaussian_filter(temp, sigmas, 0, mode='constant', cval=0)\n",
    "# \tgaussian_map /= np.max(gaussian_map)\n",
    "# \treturn gaussian_map.astype(np.float32)\n",
    "\n",
    "def patches2image(patches,overlap_rate,sigma=4.0/8):\n",
    "    #不适合\n",
    "    if patches[0].ndim == 2:\n",
    "        patches = np.array(patches)[np.newaxis,...]\n",
    "    patch_t = patches[0].shape[0]\n",
    "    patch_size = patches[0].shape[1] #1024\n",
    "    stride = int(patch_size * (1 - overlap_rate)) #512\n",
    "    patch_num = int(np.ceil(np.sqrt(len(patches)))) #5\n",
    "    image_size = (patch_num+1) * stride # 3072\n",
    "    image = np.zeros((patch_t,image_size, image_size), dtype=np.float32)\n",
    "    normal_map = np.zeros((patch_t,image_size, image_size), dtype=np.float32)\n",
    "    gaussian_map = get_gaussian((patch_size, patch_size), sigma)\n",
    "    gaussian_map = np.tile(gaussian_map[np.newaxis,...],(patch_t,1,1))\n",
    "\n",
    "    gaussian_map = np.ones_like(gaussian_map)\n",
    "\n",
    "    for i in range(patch_num):\n",
    "        for j in range(patch_num):\n",
    "            patch = patches[i * patch_num + j]\n",
    "            image[:,i * stride:i * stride + patch_size, j * stride:j * stride + patch_size] += patch * gaussian_map\n",
    "            normal_map[:,i * stride:i * stride + patch_size, j * stride:j * stride + patch_size] += gaussian_map\n",
    "    image = image / normal_map\n",
    "\n",
    "    return image.astype(np.uint16)\n",
    "\n",
    "def patches2image2(patches,overlap_rate):\n",
    "    # 小瑕疵\n",
    "    if patches[0].ndim == 2:\n",
    "        patches = np.array(patches)[np.newaxis,...]\n",
    "    patch_t = patches[0].shape[0]\n",
    "    patch_size = patches[0].shape[1] #1024\n",
    "    stride = int(patch_size * (1 - overlap_rate)) #512\n",
    "    patch_num = int(np.ceil(np.sqrt(len(patches)))) #5\n",
    "    image_size = (patch_num+1) * stride # 3072\n",
    "    image = np.zeros((patch_t,image_size, image_size), dtype=np.float32)\n",
    "    count_map = np.zeros((patch_t,image_size, image_size), dtype=np.float32)\n",
    "\n",
    "\n",
    "    for i in trange(patch_num):\n",
    "        for j in trange(patch_num):\n",
    "            patch = patches[i * patch_num + j]\n",
    "            image[:,i * stride:i * stride + patch_size, j * stride:j * stride + patch_size] += patch\n",
    "            count_map[:,i * stride:i * stride + patch_size, j * stride:j * stride + patch_size] += np.where(patch>0,1,0)\n",
    "    count_map[count_map==1] = 0\n",
    "    count_map[count_map==2] = 1/2\n",
    "    count_map[count_map==3] = 1/3\n",
    "    count_map[count_map==4] = 1/4\n",
    "    image = image * count_map\n",
    "\n",
    "    return image.astype(np.uint16)\n",
    "\n",
    "def patches2image3(patches,overlap_rate):\n",
    "    #崩溃\n",
    "    print('patches2image ing...')\n",
    "    if patches[0].ndim == 2:\n",
    "        patches = np.array(patches)[np.newaxis,...]\n",
    "    patch_t = patches[0].shape[0]\n",
    "    patch_size = patches[0].shape[1] #1024\n",
    "    stride = int(patch_size * (1 - overlap_rate)) #512\n",
    "    patch_num = int(np.ceil(np.sqrt(len(patches)))) #5\n",
    "    image_size = (patch_num+1) * stride # 3072\n",
    "\n",
    "    # image = np.zeros((patch_t,image_size, image_size), dtype=np.float32)\n",
    "    # #image的每一个值是一个列表，是所有patch在该位置的值的列表\n",
    "    # for i in trange(patch_num):\n",
    "    #     for j in trange(patch_num):\n",
    "    #         patch = patches[i * patch_num + j]\n",
    "    #         #把patch的值append到image的对应位置的list\n",
    "    #         image[:,i * stride:i * stride + patch_size, j * stride:j * stride + patch_size].append(patch)\n",
    "    # #对image的每一个列表取众数\n",
    "    # for i in trange(image.shape[0]):\n",
    "    #     for j in trange(image.shape[1]):\n",
    "    #         for k in trange(image.shape[2]):\n",
    "    #             image[i,j,k] = np.argmax(np.bincount(image[i,j,k]))\n",
    "\n",
    "    # 维度是 (t, image_size, image_size)，每个位置是一个列表，用来存储该位置的所有patch\n",
    "    image = np.empty((patch_t, image_size, image_size), dtype=object)\n",
    "    print('image.shape:',image.shape)\n",
    "    # 初始化每个位置的列表\n",
    "    for t in range(patch_t):\n",
    "        for i in range(image_size):\n",
    "            for j in range(image_size):\n",
    "                image[t, i, j] = []\n",
    "\n",
    "    # 将patch添加到对应位置的列表中\n",
    "    for idx in trange(len(patches)):\n",
    "        i = idx // patch_num  # 计算行号\n",
    "        j = idx % patch_num   # 计算列号\n",
    "        patch = patches[idx]\n",
    "\n",
    "\n",
    "        for t in range(patch_t):\n",
    "            for x in range(patch_size):\n",
    "                for y in range(patch_size):\n",
    "                    image[t, i * stride + x, j * stride + y].append(patch[t, x, y])\n",
    "\n",
    "    # # 计算每个位置的众数\n",
    "    # for i in trange(image.shape[1]):\n",
    "    #     for j in trange(image.shape[2]):\n",
    "    #         for t in range(patch_t):\n",
    "    #             # 获取当前位置的所有patch，并计算众数\n",
    "    #             patch_list = image[t, i, j]\n",
    "    #             if patch_list:\n",
    "    #                 image[t, i, j] = np.argmax(np.bincount(patch_list))\n",
    "\n",
    "    return image.astype(np.uint16)\n",
    "\n",
    "def patches2image4(patches,overlap_rate):\n",
    "    #慢？\n",
    "    print('patches2image ing...')\n",
    "    if patches[0].ndim == 2:\n",
    "        patches = np.array(patches)[np.newaxis,...]\n",
    "    patch_t = patches[0].shape[0]\n",
    "    patch_size = patches[0].shape[1] #1024\n",
    "    stride = int(patch_size * (1 - overlap_rate)) #512\n",
    "    patch_num = int(np.ceil(np.sqrt(len(patches)))) #5\n",
    "    image_size = (patch_num+1) * stride # 3072\n",
    "\n",
    "    group = [0,1,0,1,0,\n",
    "             2,3,2,3,2,\n",
    "             0,1,0,1,0,\n",
    "             2,3,2,3,2,\n",
    "             0,1,0,1,0]\n",
    "\n",
    "    image = np.zeros((patch_t,image_size, image_size), dtype=np.uint16)\n",
    "    for t in trange(patch_t):\n",
    "        empty_image_4 = np.ones((image_size, image_size,4), dtype=np.uint16) * (-1)\n",
    "        image_t = np.zeros((image_size, image_size), dtype=np.uint16)\n",
    "        for i in range(patch_num):\n",
    "            for j in range(patch_num):\n",
    "                patch = patches[i * patch_num + j][t]\n",
    "                empty_image_4[i * stride:i * stride + patch_size, j * stride:j * stride + patch_size, group[i*patch_num + j]] = patch\n",
    "        for i in range(image_size):\n",
    "            for j in range(image_size):\n",
    "                #排除-1\n",
    "                image_t[i,j] = np.argmax(np.bincount(empty_image_4[i,j][empty_image_4[i,j] != -1]))\n",
    "\n",
    "\n",
    "        image[t] = image_t\n",
    "    return image.astype(np.uint16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patch: l1-actin-0000_result.tif\n",
      "Processing patch: l1-actin-0001_result.tif\n",
      "Processing patch: l1-actin-0002_result.tif\n",
      "Processing patch: l1-actin-0003_result.tif\n",
      "Processing patch: l1-actin-0004_result.tif\n",
      "Processing patch: l1-actin-0005_result.tif\n",
      "Processing patch: l1-actin-0006_result.tif\n",
      "Processing patch: l1-actin-0007_result.tif\n",
      "Processing patch: l1-actin-0008_result.tif\n",
      "Processing patch: l1-actin-0009_result.tif\n",
      "Processing patch: l1-actin-0010_result.tif\n",
      "Processing patch: l1-actin-0011_result.tif\n",
      "Processing patch: l1-actin-0012_result.tif\n",
      "Processing patch: l1-actin-0013_result.tif\n",
      "Processing patch: l1-actin-0014_result.tif\n",
      "Processing patch: l1-actin-0015_result.tif\n",
      "Processing patch: l1-actin-0016_result.tif\n",
      "Processing patch: l1-actin-0017_result.tif\n",
      "Processing patch: l1-actin-0018_result.tif\n",
      "Processing patch: l1-actin-0019_result.tif\n",
      "Processing patch: l1-actin-0020_result.tif\n",
      "Processing patch: l1-actin-0021_result.tif\n",
      "Processing patch: l1-actin-0022_result.tif\n",
      "Processing patch: l1-actin-0023_result.tif\n",
      "Processing patch: l1-actin-0024_result.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "\n",
    "patches_path = '/share/data/CryoET_Data/lizhuo/data_for_liushuo/3D_data_with_mask/l1/patches/results_mapping'\n",
    "save_path = patches_path.split('patches')[0]\n",
    "patch_files = [f for f in os.listdir(patches_path) if f.endswith('.tif')]\n",
    "patch_files = natsorted(patch_files)\n",
    "patches = []\n",
    "for patch_file in patch_files:\n",
    "    print(f\"Processing patch: {patch_file}\")\n",
    "    patch = tiff.imread(os.path.join(patches_path, patch_file))\n",
    "    patches.append(patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patches2image ing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [22:47<00:00, 17.09s/it]\n"
     ]
    }
   ],
   "source": [
    "empty_image = patches2image4(patches,0.5)\n",
    "tiff.imwrite(os.path.join(save_path, 'result4.tif'), empty_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_image[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:11<04:37, 11.56s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "#image = patches2image(patches,overlap_rate = 0.5)\n",
    "image = patches2image3(patches,overlap_rate = 0.5)\n",
    "tiff.imwrite(os.path.join(save_path, 'result3.tif'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.99it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.12it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.64it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.68it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.16it/s]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "patches_path = '/share/data/CryoET_Data/lizhuo/data_for_liushuo/3D_data_with_mask/1/patches/results_mapping'\n",
    "save_path = patches_path.split('patches')[0]\n",
    "patch_files = [f for f in os.listdir(patches_path) if f.endswith('.tif')]\n",
    "patch_files = natsorted(patch_files)\n",
    "patches = []\n",
    "for patch_file in patch_files:\n",
    "    patch = tiff.imread(os.path.join(patches_path, patch_file))\n",
    "    patches.append(patch)\n",
    "image = patches2image2(patches,overlap_rate = 0.5)\n",
    "tiff.imwrite(os.path.join(save_path, 'result2.tif'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m list2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 使用zip将两个列表逐个合并\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m merged_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(chain(a, [b])) \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(list1, list2)]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_list)\n",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m list2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 使用zip将两个列表逐个合并\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m merged_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(list1, list2)]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_list)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "list1 = [[1, 1], 2]\n",
    "list2 = [3, 4]\n",
    "\n",
    "# 使用zip将两个列表逐个合并\n",
    "merged_list = [list(chain(a, [b])) for a, b in zip(list1, list2)]\n",
    "\n",
    "print(merged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'zip' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlist1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'zip' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(zip(list1, list2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[],[]]\n",
    "a.append(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.empty((5,3 ,3 ), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[0][0][0] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[list([]), None, None],\n",
       "        [None, None, None],\n",
       "        [None, None, None]],\n",
       "\n",
       "       [[None, None, None],\n",
       "        [None, None, None],\n",
       "        [None, None, None]],\n",
       "\n",
       "       [[None, None, None],\n",
       "        [None, None, None],\n",
       "        [None, None, None]],\n",
       "\n",
       "       [[None, None, None],\n",
       "        [None, None, None],\n",
       "        [None, None, None]],\n",
       "\n",
       "       [[None, None, None],\n",
       "        [None, None, None],\n",
       "        [None, None, None]]], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "\n",
    "patch_label = np.zeros((1,3072,3072),dtype=np.uint16)\n",
    "for i in range(25):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    patch_label[0,row*512+10:row*512+1014,col*512+10:col*512+10+i] = i\n",
    "    patch_label[0,row*512+10:row*512+1014,col*512+1014:col*512+1014-i] = i\n",
    "    patch_label[0,row*512+10:row*512+10+i,col*512+10:col*512+1014] = i\n",
    "    patch_label[0,row*512+1014:row*512+1014-i,col*512+10:col*512+1014] = i\n",
    "\n",
    "tiff.imwrite('/share/data/CryoET_Data/lizhuo/data_for_liushuo/3D_data_with_mask/patches_label.tif',patch_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpatch\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patch' is not defined"
     ]
    }
   ],
   "source": [
    "patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condasam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
